{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c44d7f-3134-412a-be94-4c36345cd849",
   "metadata": {},
   "source": [
    "# Cluster analysis of image patches vectorized by EfficientNet B0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcafb79b-aab7-4226-a806-2f56041bf1f7",
   "metadata": {},
   "source": [
    "# Set up EfficientNet B0 with wieghts trained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104d9c2-51e2-45d5-b9c6-ac82ff6b7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np   \n",
    "import cv2\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724aff55-471a-46cf-ad70-e022197284e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb65af5-2b77-45c9-b0ee-9cd2afb3077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2327e8b7-832f-42b7-82eb-f5bf558f144e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "# Instantiate the EfficientNetB0 architecture\n",
    "model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008475b8-d7d0-4318-b72c-94983c81d50a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31184585-01eb-4d6c-b84d-6392702cdeba",
   "metadata": {},
   "source": [
    "Images from: https://github.com/basveeling/pcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55667bbc-cfa9-41a3-8bc1-ebe6f086d24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#show some images as an example\n",
    "'''\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File('/Users/scott/Desktop/cluster_test/camelyonpatch_level_2_split_train_x.h5', 'r') as file:\n",
    "    # Access the 'x' dataset from the file\n",
    "    x_train = file['x']\n",
    "\n",
    "    # Display the first three images\n",
    "    for i in range(3):\n",
    "        image = x_train[i]  # Get the image data\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')  # Remove axis labels\n",
    "        plt.show()\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcceca4-b561-474e-89fd-ebdb5b97bfe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File('/Users/scott/Desktop/cluster_test/camelyonpatch_level_2_split_train_x.h5', 'r') as file:\n",
    "    # Access the 'x' dataset from the file\n",
    "    x_train = file['x']\n",
    "\n",
    "    # Get the first image from the dataset\n",
    "    image = x_train[0]\n",
    "\n",
    "    # Obtain the height, width, and channels of the image\n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    print(\"Height:\", height)\n",
    "    print(\"Width:\", width)\n",
    "    print(\"Channels:\", channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23ffb8-1cad-45f1-a135-b7b32270ffeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#store the dataset x of the huge h5 file in the variable x_train\n",
    "file = h5py.File('/Users/scott/Desktop/cluster_test/camelyonpatch_level_2_split_train_x.h5', 'r')\n",
    "\n",
    "# Access the dataset 'x'\n",
    "x_train = file['x'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638522c4-732e-43d2-8623-84c847bd770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images\n",
    "print(\"Number of images in x_train:\", x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf390a-7a72-413d-9c72-72fcc08f69d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#show an image of your choice\n",
    "image = x_train[9]  # Get the image data\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Remove axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f560e4-3f94-45c1-bf9b-29a89bf1cf82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get features from second to last layer (by ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e3ce40-ba88-48f5-9e90-7918c3f41389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2e800-37c8-4850-a6e2-1b65e12e3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess by adjusting the images to the expected size from 96x96 --> 224x224\n",
    "# Get the number of images\n",
    "num_images = x_train.shape[0]\n",
    "\n",
    "# Create an empty array for resized images\n",
    "resized_images = np.empty((num_images, 224, 224, 3), dtype=np.uint8)\n",
    "\n",
    "# Resize each image to 224x224\n",
    "for i in range(num_images):\n",
    "    image = x_train[i]\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    resized_images[i] = resized_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9fc8d-6cbe-417e-8c5c-d57f65d72ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I don't know wether this is necessary?\n",
    "\n",
    "'''\n",
    "The preprocessing logic has been included in the efficientnet model implementation. \n",
    "Users are no longer required to call this method to normalize the input data. \n",
    "This method does nothing and only kept as a placeholder to align \n",
    "the API surface between old and new version of model.\n",
    "'''\n",
    "\n",
    "# Preprocess the images in x_train to match the input shape of the EfficientNet-B0 model:\n",
    "x_train_preprocessed = tf.keras.applications.efficientnet.preprocess_input(resized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bbb006-c9a5-47ef-9f78-042d3b3d03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I get the problem\n",
    "\n",
    "# Obtain the features by applying 2D average pooling to the output of the pre-activation layer:\n",
    "features = model.predict(x_train_preprocessed)\n",
    "features_pooled = np.mean(features, axis=(1, 2))  # Apply 2D average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8b525-6fef-42e5-ba03-c9920d793bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features to a CSV file:\n",
    "df = pd.DataFrame(features_pooled)\n",
    "df.to_csv('/Users/scott/Desktop/cluster_test/features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv4_tf_clustering",
   "language": "python",
   "name": "condaenv4_tf_clustering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
